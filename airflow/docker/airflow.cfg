[core]
# DAGs目录
dags_folder = /opt/airflow/dags



# 执行器类型
executor = LocalExecutor

# 并行度设置
parallelism = 32
dag_concurrency = 16
max_active_runs_per_dag = 16
max_active_tasks_per_dag = 16

# DAG加载设置
load_examples = False
load_default_connections = False

# 安全设置
fernet_key = ${AIRFLOW_FERNET_KEY}

# 时区设置
default_timezone = Asia/Shanghai

[logging]
# 日志级别
logging_level = INFO

# 日志格式
log_format = [%%(asctime)s] {%%(filename)s:%%(lineno)d} %%(levelname)s - %%(message)s
simple_log_format = %%(asctime)s %%(levelname)s - %%(message)s

# 日志处理器
logging_config_class = airflow.config_templates.airflow_local_settings.DEFAULT_LOGGING_CONFIG

# 远程日志基础路径
remote_base_log_folder = 
remote_log_conn_id = 

# 日志配置
base_log_folder = /opt/airflow/logs
remote_logging = False 

[webserver]
# Web服务器设置
web_server_host = 0.0.0.0
web_server_port = 8080
web_server_worker_timeout = 120
worker_refresh_batch_size = 1
worker_refresh_interval = 6000

# 认证设置
authenticate = True
auth_backend = airflow.contrib.auth.backends.password_auth

# 安全设置
secret_key = ${AIRFLOW_SECRET_KEY}

# 会话设置
session_lifetime_minutes = 43200

# 页面设置
page_size = 100
default_dag_run_display_number = 25

[scheduler]
# 调度器设置
scheduler_heartbeat_sec = 5
scheduler_health_check_threshold = 30
max_threads = 2
catchup_by_default = False
dag_dir_list_interval = 300
child_process_timeout = 60

# DAG文件处理
dag_file_processor_timeout = 50
min_file_process_interval = 30
max_dagruns_to_create_per_loop = 10
max_dagruns_per_loop_to_schedule = 20

[celery]
# Celery设置（如果使用CeleryExecutor）
celery_app_name = airflow.executors.celery_executor
worker_concurrency = 16

[smtp]
# 邮件设置
smtp_host = ${AIRFLOW_SMTP_HOST}
smtp_starttls = True
smtp_ssl = False
smtp_port = 587
smtp_mail_from = ${AIRFLOW_SMTP_FROM}
smtp_user = ${AIRFLOW_SMTP_USER}
smtp_password = ${AIRFLOW_SMTP_PASSWORD}

[api]
# API设置
auth_backend = airflow.api.auth.backend.basic_auth

[operators]
# 操作符设置
default_owner = airflow
default_cpus = 1
default_ram = 512
default_disk = 512
default_gpus = 0

[database]
# 数据库配置
sql_alchemy_conn = mysql+pymysql://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@${AIRFLOW_DB_HOST}:${AIRFLOW_DB_PORT}/${AIRFLOW_DB_NAME}
# 数据库连接池设置
sql_alchemy_pool_size = 5
sql_alchemy_pool_recycle = 3600
sql_alchemy_pool_pre_ping = True
sql_alchemy_max_overflow = 10