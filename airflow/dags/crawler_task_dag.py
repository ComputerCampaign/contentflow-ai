from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.operators.dummy_operator import DummyOperator
from airflow.utils.dates import days_ago
from airflow.utils.trigger_rule import TriggerRule

from utils.utils import (
    get_pending_task, handle_task_success, handle_task_failure,
    submit_task_via_api, poll_task_status, api_client
)
from config.config import DAG_CONFIG, TASK_TYPES
import logging

# DAGé»˜è®¤å‚æ•°
default_args = DAG_CONFIG['default_args'].copy()
default_args.update({
    'start_date': days_ago(1),
    'retries': 1,
    'retry_delay': timedelta(minutes=2),
})

# åˆ›å»ºDAG - ä¼˜åŒ–åçš„ç®€åŒ–ç‰ˆæœ¬
dag = DAG(
    'crawler_task_pipeline_optimized',
    default_args=default_args,
    description='ä¼˜åŒ–åçš„çˆ¬è™«ä»»åŠ¡å¤„ç†æµæ°´çº¿ - ç®€åŒ–æµç¨‹ï¼Œé›†æˆç»“æœä¸Šä¼ ',
    schedule_interval=timedelta(minutes=20),  # ç¼©çŸ­è°ƒåº¦é—´éš”
    catchup=False,
    tags=['crawler', 'pipeline', 'optimized'],
)

def process_crawler_task(**context):
    """
    ä¼˜åŒ–åçš„çˆ¬è™«ä»»åŠ¡å¤„ç†å‡½æ•° - é›†æˆè·å–ã€æ‰§è¡Œã€è½®è¯¢å’Œç»“æœå¤„ç†
    """
    try:
        logging.info("ğŸš€ [OPTIMIZED] å¼€å§‹å¤„ç†çˆ¬è™«ä»»åŠ¡...")
        
        # 1. è·å–å¾…æ‰§è¡Œä»»åŠ¡
        logging.info("ğŸ“‹ [OPTIMIZED] è·å–å¾…æ‰§è¡Œçš„çˆ¬è™«ä»»åŠ¡...")
        task = api_client.get_next_task(TASK_TYPES['CRAWLER'].upper())
        
        if not task:
            logging.info("ğŸ“­ [OPTIMIZED] æ²¡æœ‰å¾…æ‰§è¡Œçš„çˆ¬è™«ä»»åŠ¡ï¼Œè·³è¿‡æœ¬æ¬¡è°ƒåº¦")
            return {'success': True, 'message': 'æ²¡æœ‰å¾…æ‰§è¡Œä»»åŠ¡', 'task_processed': False}
        
        task_id = task['id']
        task_name = task.get('name', 'æœªçŸ¥ä»»åŠ¡')
        logging.info(f"ğŸ“‹ [OPTIMIZED] æ‰¾åˆ°å¾…æ‰§è¡Œä»»åŠ¡: {task_id} ({task_name})")
        
        # å­˜å‚¨ä»»åŠ¡ä¿¡æ¯åˆ°XCom
        context['task_instance'].xcom_push(key='crawler_task', value=task)
        context['task_instance'].xcom_push(key='task_id', value=task_id)
        
        # 2. æäº¤ä»»åŠ¡æ‰§è¡Œ
        logging.info(f"ğŸ”„ [OPTIMIZED] æäº¤ä»»åŠ¡ {task_id} æ‰§è¡Œè¯·æ±‚...")
        submit_result = api_client.execute_task(task_id)
        logging.info(f"âœ… [OPTIMIZED] ä»»åŠ¡ {task_id} æäº¤æˆåŠŸ: {submit_result}")
        
        # 3. è½®è¯¢ä»»åŠ¡çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        import time
        max_wait_time = 1800  # æœ€å¤§ç­‰å¾…30åˆ†é’Ÿ
        poll_interval = 15    # è½®è¯¢é—´éš”15ç§’
        start_time = time.time()
        
        logging.info(f"â³ [OPTIMIZED] å¼€å§‹è½®è¯¢ä»»åŠ¡ {task_id} çŠ¶æ€...")
        
        while time.time() - start_time < max_wait_time:
            task_status = api_client.get_task_status(task_id)
            
            if not task_status:
                logging.warning(f"âš ï¸ [OPTIMIZED] æ— æ³•è·å–ä»»åŠ¡ {task_id} çŠ¶æ€ï¼Œç»§ç»­ç­‰å¾…...")
                time.sleep(poll_interval)
                continue
            
            current_status = task_status.get('status')
            elapsed_time = int(time.time() - start_time)
            
            if current_status == 'completed':
                logging.info(f"âœ… [OPTIMIZED] ä»»åŠ¡ {task_id} æ‰§è¡ŒæˆåŠŸï¼è€—æ—¶: {elapsed_time}ç§’")
                
                # 4. å¤„ç†æˆåŠŸç»“æœ
                try:
                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆ
                    api_client.update_task_status(task_id, 'completed', result='ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ')
                    logging.info(f"ğŸ“Š [OPTIMIZED] ä»»åŠ¡ {task_id} çŠ¶æ€å·²æ›´æ–°ä¸ºå®Œæˆ")
                    
                    # æ³¨æ„ï¼šçˆ¬è™«ç»“æœä¸Šä¼ ç”±çˆ¬è™«æœåŠ¡è‡ªåŠ¨å®Œæˆï¼Œæ— éœ€åœ¨DAGä¸­å¤„ç†
                    logging.info(f"ğŸ“¤ [OPTIMIZED] çˆ¬è™«ç»“æœå°†ç”±çˆ¬è™«æœåŠ¡è‡ªåŠ¨ä¸Šä¼ åˆ°åç«¯")
                    
                except Exception as e:
                    logging.error(f"âŒ [OPTIMIZED] å¤„ç†ä»»åŠ¡æˆåŠŸç»“æœæ—¶å‡ºé”™: {str(e)}")
                
                return {
                    'success': True,
                    'task_id': task_id,
                    'status': 'completed',
                    'message': 'ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ',
                    'elapsed_time': elapsed_time,
                    'task_processed': True
                }
                
            elif current_status == 'failed':
                error_message = task_status.get('error_message', 'æœªçŸ¥é”™è¯¯')
                logging.error(f"âŒ [OPTIMIZED] ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {error_message}")
                
                # å¤„ç†å¤±è´¥ç»“æœ
                try:
                    api_client.update_task_status(task_id, 'failed', error_message=error_message)
                    logging.info(f"ğŸ“Š [OPTIMIZED] ä»»åŠ¡ {task_id} çŠ¶æ€å·²æ›´æ–°ä¸ºå¤±è´¥")
                except Exception as e:
                    logging.error(f"âŒ [OPTIMIZED] æ›´æ–°å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
                
                return {
                    'success': False,
                    'task_id': task_id,
                    'status': 'failed',
                    'message': f'ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {error_message}',
                    'elapsed_time': elapsed_time,
                    'task_processed': True
                }
                
            elif current_status in ['running', 'pending']:
                # æ¯åˆ†é’Ÿè¾“å‡ºä¸€æ¬¡è¿›åº¦
                if elapsed_time % 60 == 0 and elapsed_time > 0:
                    logging.info(f"â³ [OPTIMIZED] ä»»åŠ¡ {task_id} ä»åœ¨æ‰§è¡Œä¸­ï¼Œå·²ç­‰å¾… {elapsed_time}ç§’")
                time.sleep(poll_interval)
                continue
            else:
                logging.warning(f"âš ï¸ [OPTIMIZED] ä»»åŠ¡ {task_id} çŠ¶æ€æœªçŸ¥: {current_status}")
                time.sleep(poll_interval)
                continue
        
        # è¶…æ—¶å¤„ç†
        elapsed_time = int(time.time() - start_time)
        logging.error(f"â° [OPTIMIZED] ä»»åŠ¡ {task_id} æ‰§è¡Œè¶…æ—¶ï¼Œå·²ç­‰å¾… {elapsed_time}ç§’")
        
        try:
            api_client.update_task_status(task_id, 'failed', error_message=f'ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ï¼Œå·²ç­‰å¾… {elapsed_time}ç§’')
        except Exception as e:
            logging.error(f"âŒ [OPTIMIZED] æ›´æ–°è¶…æ—¶çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
        
        return {
            'success': False,
            'task_id': task_id,
            'status': 'timeout',
            'message': f'ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ï¼Œå·²ç­‰å¾… {elapsed_time}ç§’',
            'elapsed_time': elapsed_time,
            'task_processed': True
        }
        
    except Exception as e:
        logging.error(f"ğŸ’¥ [OPTIMIZED] å¤„ç†çˆ¬è™«ä»»åŠ¡æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return {
            'success': False,
            'status': 'error',
            'message': f'å¤„ç†ä»»åŠ¡æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}',
            'task_processed': False
        }

# ä¼˜åŒ–åçš„å•ä¸€ä»»åŠ¡å¤„ç†èŠ‚ç‚¹
process_crawler_tasks = PythonOperator(
    task_id='process_crawler_tasks',
    python_callable=process_crawler_task,
    dag=dag,
)

# ä»»åŠ¡å®Œæˆæ ‡è®°
task_complete = DummyOperator(
    task_id='task_complete',
    dag=dag,
)

# ç®€åŒ–çš„ä»»åŠ¡ä¾èµ–å…³ç³»
process_crawler_tasks >> task_complete